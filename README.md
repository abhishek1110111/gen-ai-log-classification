# ğŸ§  GenAI + NLP Log Classification System

A hybrid log classification system built from scratch using **Regex**, **BERT**, **Deepseek R1, LLaMA (LLMs)**, and **Logistic Regression** to categorize system logs into actionable categories like *Security Alerts*, *Workflow Errors*, *User Actions*, and more. The system leverages both traditional NLP and modern Generative AI, wrapped in a production-ready **FastAPI** interface.

> ğŸš€ Designed to support DevOps and SRE teams with smarter debugging, anomaly detection, and operational efficiencyâ€”while optimizing cost and improving accuracy.

---

## ğŸ“Œ Project Highlights

- ğŸ§¹ **Hybrid Architecture** combining Regex, BERT, Logistic Regression, and LLMs (Deepseek R1, LLaMA)
- ğŸ§  **Zero-shot/few-shot classification** using LLaMA when labeled data is scarce
- âš¡ **FastAPI-powered REST API** for real-time log analysis and integration
- ğŸ“Š Designed for **real-world log analytics** in production environments
- â™»ï¸ **Scalable & cost-efficient**, ideal for large-scale DevOps pipelines

---

## ğŸ› ï¸ Tech Stack

| Component     | Technology                        |
| ------------- | --------------------------------- |
| NLP/Embedding | BERT, Regex, Sentence Transformer |
| GenAI         | Deepseek R1, LLaMA/LLMs           |
| Classifier    | Logistic Regression               |
| Backend/API   | FastAPI                           |
| Language      | Python                            |

---

## ğŸ§± Architecture Overview
![architecture](resources/project_architecture.png)


---

## ğŸ” Classification Approaches

1. **Regular Expression (Regex)**

   - Rule-based, fast classification for well-defined log patterns.

2. **Sentence Transformer + Logistic Regression**

   - Uses embeddings from Sentence Transformers and Logistic Regression for supervised classification when labeled data is available.

3. **LLMs (Large Language Models)**

   - LLaMA or Deepseek R1 used for complex, low-data scenarios (zero/few-shot learning).

### ğŸ”¹ Classification Pipeline

1. **Regex Classification**\
   Quick detection using predefined rules.

2. **Unknown Logs â†’ BERT / Deepseek R1 / LLaMA**

   - If **enough labeled data** â†’ BERT classifier
   - If **few or no samples** â†’ LLaMA-powered zero/few-shot classification

3. **Output** â†’ Results are returned with classified log categories like `Security Alert`, `Workflow Error`, `User Action`, etc.

> âœ… This hybrid approach ensures high accuracy, scalability, and optimized cost-performance balance.

---

## ğŸ’¡ Why Hybrid Classification?

| Benefit                  | Description                                                                 |
| ------------------------ | --------------------------------------------------------------------------- |
| ğŸ’¸ **Cost Optimization** | Prioritizes fast, cheap methods (Regex/LogReg), using LLMs only when needed |
| ğŸŒŸ **Better Accuracy**   | Combines rule-based precision with contextual inference from ML/LLM         |
| ğŸ“ˆ **Scalability**       | Easily adapts to new log types with minimal retraining                      |
| ğŸ”§ **Maintainability**   | Modular design enables easy upgrades and experimentation                    |

---

## ğŸ“ Folder Structure

```
.
â”œâ”€â”€ main.py                   # FastAPI server code
â”œâ”€â”€ requirements.txt          # Project dependencies
â”œâ”€â”€ resources/                # Output CSVs, test files, project image
â”œâ”€â”€ training_dataset/
â”‚   â”œâ”€â”€ dataset/              # Labeled training datasets
â”‚   â”œâ”€â”€ models/               # Saved Sentence Transformer and Logistic Regression models
â”‚   â””â”€â”€ notebooks/            # Jupyter notebooks for model training
â”œâ”€â”€ regex_classifier.py       # Regex-based classification logic
â”œâ”€â”€ bert_classifier.py        # BERT model for supervised classification
â”œâ”€â”€ llm_classifier.py         # LLM (Deepseek R1/LLaMA) classification
|__ .env                      # Need to API integrated LLM model
â””â”€â”€ venv/                     # Virtual environment (optional, ignored in .git)
```

---

## âš™ï¸ Setup Instructions

1. **Install Dependencies**

   Make sure Python is installed, then install the required packages:

   ```bash
   pip install -r requirements.txt
   ```

2. **Run the FastAPI Server**

   Start the server:

   ```bash
   uvicorn main:app --reload
   ```

   Once the server is up, access:

   - API base: `http://127.0.0.1:8000/`
   - Swagger UI: `http://127.0.0.1:8000/docs`
   - ReDoc: `http://127.0.0.1:8000/redoc`

---

## ğŸš€ Usage

Upload a CSV file to the FastAPI endpoint for classification. The file **must include** the following columns:

- `source`
- `log_message`

The system will return a CSV file with an additional column:

- `target_label`: the predicted category for each log entry.

---

## ğŸ§ª API Testing

- You can test the API using **Postman** or any other API client.
- Use the `/classify/` POST endpoint and upload a `.csv` file in `multipart/form-data` format.

